{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_df = pd.read_csv('../InputData/sad.csv',index_col=0)\n",
    "happy_df = pd.read_csv('../InputData/happy.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 = happy, 1 = sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_sad = ['Sad']*sad_df.shape[0]\n",
    "mood_happy = ['Happy']*happy_df.shape[0]\n",
    "sad_df['Moods'] = mood_sad\n",
    "happy_df['Moods'] = mood_happy\n",
    "sad_df['mood'] = ['1']*sad_df.shape[0]\n",
    "happy_df['mood'] = ['0']*happy_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5301, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>release_date</th>\n",
       "      <th>length</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "      <th>Moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>everything i wanted</td>\n",
       "      <td>everything i wanted</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>245425</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-14.454</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>120.006</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ghostin</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>271466</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-8.295</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>103.777</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Too Good At Goodbyes</td>\n",
       "      <td>The Thrill Of It All (Special Edition)</td>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>201000</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169</td>\n",
       "      <td>-8.237</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>91.873</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love you</td>\n",
       "      <td>WHEN WE ALL FALL ASLEEP, WHERE DO WE GO?</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>291796</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-18.435</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>137.446</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Fall Apart</td>\n",
       "      <td>Stoney (Deluxe)</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>223346</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-5.408</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>143.950</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                     album  \\\n",
       "0   everything i wanted                       everything i wanted   \n",
       "1               ghostin                             thank u, next   \n",
       "2  Too Good At Goodbyes    The Thrill Of It All (Special Edition)   \n",
       "3            i love you  WHEN WE ALL FALL ASLEEP, WHERE DO WE GO?   \n",
       "4          I Fall Apart                           Stoney (Deluxe)   \n",
       "\n",
       "          artist release_date  length  popularity  key  mode  valence  \\\n",
       "0  Billie Eilish   2019-11-13  245425          82    6     0    0.243   \n",
       "1  Ariana Grande   2019-02-08  271466          69    9     1    0.110   \n",
       "2      Sam Smith   2017-11-03  201000          74    5     1    0.476   \n",
       "3  Billie Eilish   2019-03-29  291796          80    0     1    0.120   \n",
       "4    Post Malone   2016-12-09  223346          80    8     0    0.291   \n",
       "\n",
       "   danceability  acousticness  energy  instrumentalness  liveness  loudness  \\\n",
       "0         0.704        0.9020   0.225          0.657000     0.106   -14.454   \n",
       "1         0.287        0.4180   0.364          0.000018     0.185    -8.295   \n",
       "2         0.681        0.6400   0.372          0.000000     0.169    -8.237   \n",
       "3         0.421        0.9520   0.131          0.004530     0.109   -18.435   \n",
       "4         0.556        0.0689   0.538          0.000000     0.196    -5.408   \n",
       "\n",
       "   speechiness    tempo  time_signature mood Moods  \n",
       "0       0.0994  120.006               4    1   Sad  \n",
       "1       0.0306  103.777               4    1   Sad  \n",
       "2       0.0432   91.873               4    1   Sad  \n",
       "3       0.0382  137.446               4    1   Sad  \n",
       "4       0.0382  143.950               4    1   Sad  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([sad_df,happy_df]).reset_index(drop=True)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(labels='valence',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../InputData/happy_sad_dataset.csv\",sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"../InputData/happy_sad_dataset.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df.drop(labels=['name','album','artist','release_date','length','mood','Moods','loudness','popularity'],axis=1)\n",
    "y = test_df['mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.814\n"
     ]
    }
   ],
   "source": [
    "# define the multinomial logistic regression model\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "lr_model.fit(X_train_scaled,y_train)\n",
    "# report the model performance\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>332</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>125</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          332          121\n",
       "Actual 1          125          748"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8144796380090498\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       453\n",
      "           1       0.86      0.86      0.86       873\n",
      "\n",
      "    accuracy                           0.81      1326\n",
      "   macro avg       0.79      0.79      0.79      1326\n",
      "weighted avg       0.81      0.81      0.81      1326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>319</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>120</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          319          134\n",
       "Actual 1          120          753"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.808446455505279\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.72       453\n",
      "           1       0.85      0.86      0.86       873\n",
      "\n",
      "    accuracy                           0.81      1326\n",
      "   macro avg       0.79      0.78      0.79      1326\n",
      "weighted avg       0.81      0.81      0.81      1326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the decision tree classifier instance\n",
    "dt_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fitting the model\n",
    "dt_model = dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions using the testing data\n",
    "predictions = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>343</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>100</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          343          110\n",
       "Actual 1          100          773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8416289592760181\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       453\n",
      "           1       0.88      0.89      0.88       873\n",
      "\n",
      "    accuracy                           0.84      1326\n",
      "   macro avg       0.82      0.82      0.82      1326\n",
      "weighted avg       0.84      0.84      0.84      1326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=20, random_state=78) \n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "cm_df\n",
    "\n",
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total_scale = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_RF_pred = rf_model.predict(X_total_scale)\n",
    "for index,row in test_df.iterrows():\n",
    "    if row['mood'] == y_RF_pred[index]:\n",
    "        test_df.loc[index,'RF_Results'] = 'True'\n",
    "    else:\n",
    "        test_df.loc[index,'RF_Results'] = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../analysis_data/output_data/happy_sad_with_ML.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1.4\n",
      "Accuracy score (training): 0.871\n",
      "Accuracy score (validation): 0.799\n",
      "Learning rate:  1.5\n",
      "Accuracy score (training): 0.875\n",
      "Accuracy score (validation): 0.823\n",
      "Learning rate:  1.6\n",
      "Accuracy score (training): 0.872\n",
      "Accuracy score (validation): 0.803\n",
      "Learning rate:  1.7\n",
      "Accuracy score (training): 0.852\n",
      "Accuracy score (validation): 0.790\n",
      "Learning rate:  1.8\n",
      "Accuracy score (training): 0.841\n",
      "Accuracy score (validation): 0.782\n",
      "Learning rate:  1.9\n",
      "Accuracy score (training): 0.685\n",
      "Accuracy score (validation): 0.689\n",
      "Learning rate:  2.0\n",
      "Accuracy score (training): 0.808\n",
      "Accuracy score (validation): 0.757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "learning_rates = [1.4,1.5,1.6,1.7,1.8,1.9,2.0]\n",
    "for learning_rate in learning_rates:\n",
    "   classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "   learning_rate=learning_rate,\n",
    "   max_features=5,\n",
    "   max_depth=3,\n",
    "   random_state=0)\n",
    "   classifier.fit(X_train_scaled, y_train)\n",
    "   print(\"Learning rate: \", learning_rate)\n",
    "   print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_train_scaled,\n",
    "           y_train)))\n",
    "   print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "       classifier.score(\n",
    "           X_test_scaled,\n",
    "           y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8227752639517345\n"
     ]
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "   learning_rate=1.5, max_features=5, max_depth=3, random_state=0)\n",
    "\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>320</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>102</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          320          133\n",
       "Actual 1          102          771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "   cm, index=[\"Actual 0\", \"Actual 1\"],\n",
    "   columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>320</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>102</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          320          133\n",
       "Actual 1          102          771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8227752639517345\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73       453\n",
      "           1       0.85      0.88      0.87       873\n",
      "\n",
      "    accuracy                           0.82      1326\n",
      "   macro avg       0.81      0.79      0.80      1326\n",
      "weighted avg       0.82      0.82      0.82      1326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 Spotify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_2020_df = pd.read_csv('../analysis_data/spotify_wrapped_billboard/merged.csv',index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2020 =spotify_2020_df.drop(labels=['name','song_uri','artist_name','artist_id','year','duration_ms','loudness','valence'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler_2020 = StandardScaler()\n",
    "\n",
    "# Fitting Standard Scaller\n",
    "test_scaler_2020 = scaler.fit(test_2020)\n",
    "\n",
    "# Scaling data\n",
    "test_2020_scaled = test_scaler_2020.transform(test_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2020 = rf_model.predict(test_2020_scaled)\n",
    "spotify_2020_df['mood'] = pred_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in spotify_2020_df.iterrows():\n",
    "    if row['mood'] == '1':\n",
    "        spotify_2020_df.loc[index,'Moods'] = 'Sad'\n",
    "    else:\n",
    "        spotify_2020_df.loc[index,'Moods'] = 'Happy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_2020_df.drop(labels='valence',axis=1)\n",
    "spotify_2020_df.to_csv('../analysis_data/output_data/spotify_2020_with_Moods.csv',sep=',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03ec1fe957ed77253732182cf986c2b7ae7ab3754cf1422e3161cb9dde756bbf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('FinalProject': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
